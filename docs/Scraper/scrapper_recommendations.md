# ðŸ§ª Sitemap Scraping Tool Test Cases

This document outlines various sitemap structures and complexities to ensure the scraping tool can handle diverse real-world scenarios.

---

## 1. Large-Scale and Nested Sitemaps (Sitemap Indexes)

These websites use a master **Sitemap Index File** (e.g., `sitemap_index.xml`) that points to many smaller, nested sitemaps.

| Website Type | Website/Domain (Example) | Expected Sitemap URL | Complexity to Test |
| :--- | :--- | :--- | :--- |
| **Major News/Media** | Forbes | `https://www.forbes.com/sitemap_index.xml` | Splits articles by content type and year; tests recursive index crawling. |
| **Large E-commerce** | eBay (one of many) | `https://www.ebay.com/sitemap/sitemap_index.xml` | Tests handling of extremely large, constantly changing indexes and potentially billions of URLs. |
| **Large Blog/Content** | Cup of Jo | `https://cupofjo.com/sitemap_index.xml` | Tests structure generated by standard CMS plugins (e.g., Yoast), split by posts, pages, etc. |
| **Tech/SaaS** | NerdWallet (Regional) | `https://www.nerdwallet.com/blog/wp-sitemap.xml` | Tests handling of nested regional or language-specific sitemaps (e.g., `/ca/sitemap.xml`). |

## 2. Specialized Content Sitemaps

These sitemaps include specific extensions (namespaces) which contain extra metadata. The scraper must be able to parse these specific tags in addition to the standard `<loc>` tag.

| Sitemap Type | Example Metadata Tags | Complexity to Test |
| :--- | :--- | :--- |
| **Video Sitemaps** | `<video:title>`, `<video:content_loc>`, `<video:duration>` | Tests extraction of media-specific XML attributes. |
| **News Sitemaps** | `<news:publication>`, `<news:genres>`, `<news:publication_date>` | Tests time-sensitive data extraction and specific news structure. |
| **Image Sitemaps** | `<image:loc>`, `<image:caption>` | Tests handling of sitemaps with high image counts and associated metadata. |

## 3. Compressed & Alternative File Formats

These tests verify the tool's ability to handle physical file properties and external discovery methods.

| Format Type | Example Use Case | Complexity to Test |
| :--- | :--- | :--- |
| **Gzipped Files** | Extremely large sites that compress their files (e.g., `.xml.gz`). | Checks if the scraper can successfully **decompress and parse** Gzip files on download. |
| **`robots.txt` Integration** | Any website (e.g., `https://example.com/robots.txt`). | Checks if the tool can **discover** the location of the main sitemap index by parsing the `Sitemap:` directive in the `robots.txt` file. |

## 4. Scraping Sandboxes (Contained Environment)

These resources are provided for safe, high-volume testing of core scraping mechanisms without impacting live, production sites.

| Sandbox | Primary Function |
| :--- | :--- |
| **Books to Scrape** | Basic, static content scraping (title, price, stock). |
| **Scrape This Site** | Tests more complex scenarios like forms, pagination, and dynamic (JavaScript/AJAX) content loading. |

---

### ðŸ›‘ Ethical Scraping Guidelines (Reminder)

* Always implement a reasonable **delay** (e.g., 5-10 seconds) between requests.
* Always check and **respect the directives** in the target site's `robots.txt` file.